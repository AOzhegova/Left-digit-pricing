{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32b82d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"ZP6i5f\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"ZP6i5f\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"ZP6i5f\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"nLQ81z\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.5.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"nLQ81z\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"nLQ81z\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import re\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pyfixest as pf\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format  \n",
    "pd.set_option('display.max_columns', None)  # Show all columns in DataFrame output\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "gitfolder = current_dir.parent.parent\n",
    "datafolder = Path(\"//sen/project/Psonr/Data\")\n",
    "output = gitfolder / 'Output' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e24208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing june...\n",
      "Processed june\n",
      "Processing july...\n",
      "Processed july\n",
      "Processing aug...\n",
      "Processed aug\n",
      "Processing sep...\n",
      "Processed sep\n",
      "Processing oct...\n",
      "Processed oct\n",
      "Processing nov...\n",
      "Processed nov\n"
     ]
    }
   ],
   "source": [
    "#%% Load data\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Define file paths\n",
    "base_path = Path(\"//sen/project/Psonr/Data/Aggregate Data\")\n",
    "months = [\"june\", \"july\", \"aug\", \"sep\", \"oct\", \"nov\"]\n",
    "\n",
    "# Read the first month's data to determine column structure\n",
    "sample_query = f\"SELECT * FROM read_parquet('{base_path / (months[0] + '_data_week_store_sku.parquet')}') LIMIT 1\"\n",
    "sample_data = con.execute(sample_query).df()\n",
    "\n",
    "# Detect column types\n",
    "column_types = sample_data.dtypes.map(str).replace({\n",
    "    'int64': 'BIGINT',\n",
    "    'float64': 'DOUBLE',\n",
    "    'object': 'VARCHAR'\n",
    "}).to_dict()\n",
    "\n",
    "\n",
    "# Create merged_data table with the same columns + \"ppu\"\n",
    "columns = list(sample_data.columns) + [\"ppu\"]\n",
    "column_types[\"ppu\"] = \"DOUBLE\"\n",
    "\n",
    "# Create table dynamically\n",
    "col_str = \", \".join(f\"{col} {column_types[col]}\" for col in columns)\n",
    "create_query = f\"CREATE TABLE merged_data ({col_str})\"\n",
    "con.execute(create_query)\n",
    "\n",
    "# Process each month separately and append to the table\n",
    "for month in months:\n",
    "    # Read data directly in DuckDB\n",
    "    print(f\"Processing {month}...\")\n",
    "    data_query = f\"SELECT * FROM read_parquet('{base_path / (month + '_data_week_store_sku.parquet')}')\"\n",
    "    mode_query = f\"SELECT week, sku_gtin, store_id, ppu FROM read_parquet('{base_path / (month + '_modes_week_store_sku.parquet')}')\"\n",
    "\n",
    "    # Merge inside DuckDB, ensuring column match\n",
    "    merge_query = f\"\"\"\n",
    "        INSERT INTO merged_data ({', '.join(columns)})\n",
    "        SELECT d.*, m.ppu \n",
    "        FROM ({data_query}) AS d\n",
    "        LEFT JOIN ({mode_query}) AS m \n",
    "        USING (week, sku_gtin, store_id)\n",
    "    \"\"\"\n",
    "    \n",
    "    con.execute(merge_query)\n",
    "    print(f\"Processed {month}\")\n",
    "\n",
    "df_full = con.execute(\"SELECT * FROM merged_data\").df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1c2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Function to check memory usage\n",
    "def check_memory():\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Total memory: {memory.total / (1024**3):.2f} GB\")\n",
    "    print(f\"Available memory: {memory.available / (1024**3):.2f} GB\")\n",
    "    print(f\"Used memory: {memory.used / (1024**3):.2f} GB\")\n",
    "    print(f\"Memory usage: {memory.percent}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596aa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Data filtering and subsampling\n",
    "df_filtered = df_full[(df_full['price'] > 0) & (df_full['price'] < 100) & (df_full['quantity'] > 0) &  (df_full['quantity'] < 201)]\n",
    "#df_subset['sales'] = df_subset['price'] * df_subset['quantity']\n",
    "\n",
    "df_subset = df_filtered.sample(frac=0.1, random_state=42).copy()\n",
    "del df_full, df_filtered\n",
    "gc.collect()\n",
    "\n",
    "#%%\n",
    "common_sku = pd.read_csv(datafolder / 'common_skus.csv', sep=';')\n",
    "#common_95 = pd.read_csv(datafolder / 'sku_kassalcat_top95.csv', sep=';')\n",
    "df_subset = df_subset.merge(common_sku[['sku_gtin']], on='sku_gtin', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323fe4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def krone_ends_with_nine(price):\n",
    "    \"\"\"\n",
    "    Checks if the integer part (kroner) of the price ends with 9, \n",
    "    but not if the integer part is >= 90.\n",
    "    \"\"\"\n",
    "    if pd.isna(price):\n",
    "        return False\n",
    "    kroner_part = int(price)\n",
    "    return kroner_part % 10 == 9 and kroner_part < 90\n",
    "\n",
    "def ore_ends_with_nine(price):\n",
    "    \"\"\"\n",
    "    Checks if the decimal part (øre) is exactly 0.90, 0.95, or 0.99.\n",
    "    Also accepts 0.9 as 0.90.\n",
    "    \"\"\"\n",
    "    if pd.isna(price):\n",
    "        return False\n",
    "    ore = round(price * 100) % 100  # Extract øre as an integer (e.g. 12.95 -> 95)\n",
    "    return ore in [90, 95, 99]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1518d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Calculate LDP\n",
    "df_subset.loc[:, 'krone_ends_with_nine'] =  df_subset['ppu'].apply(krone_ends_with_nine)\n",
    "df_subset.loc[:, 'ore_ends_with_nine'] = df_subset['ppu'].apply(ore_ends_with_nine)\n",
    "df_subset.loc[:, 'ends_with_nine'] = df_subset['krone_ends_with_nine'] | df_subset['ore_ends_with_nine']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d289a30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 150.00 GB\n",
      "Available memory: 76.65 GB\n",
      "Used memory: 73.35 GB\n",
      "Memory usage: 48.9%\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "product_unique = df_subset.groupby('sku_gtin', as_index=False).agg({'store_id': 'nunique', 'week': 'nunique'})\n",
    "\n",
    "product_nonunique = product_unique[(product_unique['store_id'] > 1) & (product_unique['week'] > 1)].sku_gtin.unique()\n",
    "\n",
    "df_nonunique = df_subset[df_subset['sku_gtin'].isin(product_nonunique)].copy()\n",
    "\n",
    "del df_subset\n",
    "gc.collect()\n",
    "\n",
    "check_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_nonunique['sku_gtin'] = df_nonunique['sku_gtin'].astype('category')\n",
    "df_nonunique['week'] = df_nonunique['week'].astype('category')\n",
    "df_nonunique['store_id'] = df_nonunique['store_id'].astype('category')\n",
    "df_nonunique['kjedeid'] = df_nonunique['kjedeid'].astype('category')\n",
    "df_nonunique['krone_ends_with_nine'] = df_nonunique['krone_ends_with_nine'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31b56722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: krone_ends_with_nine, Fixed effects: kjedeid+week+sku_gtin\n",
      "Inference:  \n",
      "Observations:  12035588\n",
      "\n",
      "| Coefficient   | Estimate   | Std. Error   | t value   | Pr(>|t|)   | 2.5%   | 97.5%   |\n",
      "|---------------|------------|--------------|-----------|------------|--------|---------|\n",
      "---\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s14328\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyfixest\\estimation\\feols_.py:2092: UserWarning: Empty variance-covariance matrix detected\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "model1 = pf.feols(\"krone_ends_with_nine ~ 1 | kjedeid + week + sku_gtin\", data=df_nonunique)\n",
    "\n",
    "print(model1.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad821070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FE dictionaries\n",
    "fe_dict = model1.fixef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfae081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_id FE: keys in dict are strings, so cast df to str for mapping\n",
    "chain_fe_map = fe_dict[\"C(kjedeid)\"]\n",
    "\n",
    "df_nonunique[\"chain_fe\"] = df_nonunique[\"kjedeid\"].astype(str).map(chain_fe_map)\n",
    "\n",
    "week_fe_map = fe_dict[\"C(week)\"]\n",
    "\n",
    "df_nonunique[\"week_fe\"] = df_nonunique[\"week\"].astype(str).map(week_fe_map)\n",
    "\n",
    "sku_fe_map = fe_dict[\"C(sku_gtin)\"]\n",
    "\n",
    "df_nonunique[\"sku_fe\"] = df_nonunique[\"sku_gtin\"].astype(str).map(sku_fe_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98b47867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance shares:\n",
      "  product: 0.2947\n",
      "  week: 0.0001\n",
      "  chain: 0.0047\n",
      "  residual: 0.7003\n"
     ]
    }
   ],
   "source": [
    "var_p = df_nonunique[\"sku_fe\"].var()\n",
    "var_t = df_nonunique[\"week_fe\"].var()\n",
    "var_chain = df_nonunique[\"chain_fe\"].var()\n",
    "# Residuals\n",
    "eps = model1.resid()    \n",
    "df_nonunique['resid_step1'] = eps\n",
    "var_res = eps.var()\n",
    "var_D  = df_nonunique[\"krone_ends_with_nine\"].var()\n",
    "# Variance shares\n",
    "shares = {\n",
    "    \"product\": var_p / var_D,\n",
    "    \"week\": var_t / var_D,\n",
    "    \"chain\": var_chain / var_D,\n",
    "    \"residual\": var_res / var_D\n",
    "}\n",
    "print(\"Variance shares:\")\n",
    "for k, v in shares.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e228108",
   "metadata": {},
   "source": [
    "## Regress residuals onto store FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f194525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: resid_step1, Fixed effects: store_id\n",
      "Inference:  \n",
      "Observations:  12035588\n",
      "\n",
      "| Coefficient   | Estimate   | Std. Error   | t value   | Pr(>|t|)   | 2.5%   | 97.5%   |\n",
      "|---------------|------------|--------------|-----------|------------|--------|---------|\n",
      "---\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s14328\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyfixest\\estimation\\feols_.py:2092: UserWarning: Empty variance-covariance matrix detected\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "model2 = pf.feols(\"resid_step1 ~ 1 | store_id \", data=df_nonunique)\n",
    "\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d32677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FE dictionaries\n",
    "fe_dict2 = model2.fixef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aed3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_fe_map = fe_dict2[\"C(store_id)\"]\n",
    "\n",
    "df_nonunique[\"store_fe\"] = df_nonunique[\"store_id\"].astype(str).map(store_fe_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41f13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var_store = df_nonunique[\"store_fe\"].var()\n",
    "# Residuals\n",
    "eps2 = model2.resid()    \n",
    "df_nonunique['resid_step2'] = eps2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a74678",
   "metadata": {},
   "source": [
    "## Regress residual onto interacted FE (storeXproduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5a27507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonunique['storeXproduct'] = df_nonunique['store_id'].astype(str) + \"_\" + df_nonunique['sku_gtin'].astype(str)\n",
    "df_nonunique['storeXproduct'] = df_nonunique['storeXproduct'].astype('category')\n",
    "df_nonunique['storeXweek'] = df_nonunique['store_id'].astype(str) + \"_\" + df_nonunique['week'].astype(str)\n",
    "df_nonunique['storeXweek'] = df_nonunique['storeXweek'].astype('category')\n",
    "df_nonunique['productXweek'] = df_nonunique['sku_gtin'].astype(str) + \"_\" + df_nonunique['week'].astype(str)\n",
    "df_nonunique['productXweek'] = df_nonunique['productXweek'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5684c35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: resid_step2, Fixed effects: storeXproduct+storeXweek+productXweek\n",
      "Inference:  \n",
      "Observations:  12035588\n",
      "\n",
      "| Coefficient   | Estimate   | Std. Error   | t value   | Pr(>|t|)   | 2.5%   | 97.5%   |\n",
      "|---------------|------------|--------------|-----------|------------|--------|---------|\n",
      "---\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s14328\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyfixest\\estimation\\feols_.py:2092: UserWarning: Empty variance-covariance matrix detected\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "model3 = pf.feols(\"resid_step2 ~ 1 | storeXproduct + storeXweek + productXweek\", data=df_nonunique)\n",
    "\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1410453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FE dictionaries\n",
    "fe_dict3 = model3.fixef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a1b9e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeXproduct_fe_map = fe_dict3[\"C(storeXproduct)\"]\n",
    "df_nonunique[\"storeXproduct_fe\"] = df_nonunique[\"storeXproduct\"].astype(str).map(storeXproduct_fe_map)\n",
    "storeXweek_fe_map = fe_dict3[\"C(storeXweek)\"]\n",
    "df_nonunique[\"storeXweek_fe\"] = df_nonunique[\"storeXweek\"].astype(str).map(storeXweek_fe_map)\n",
    "productXweek_fe_map = fe_dict3[\"C(productXweek)\"]\n",
    "df_nonunique[\"productXweek_fe\"] = df_nonunique[\"productXweek\"].astype(str).map(productXweek_fe_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b4dc0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance shares:\n",
      "  product: 0.2947\n",
      "  week: 0.0001\n",
      "  chain: 0.0047\n",
      "  store: 0.0011\n",
      "  storeXproduct: 0.4868\n",
      "  storeXweek: 0.0042\n",
      "  productXweek: 0.0814\n",
      "  residual: 0.1397\n"
     ]
    }
   ],
   "source": [
    "var_p = df_nonunique[\"sku_fe\"].var()\n",
    "var_t = df_nonunique[\"week_fe\"].var()\n",
    "var_chain = df_nonunique[\"chain_fe\"].var()\n",
    "var_store = df_nonunique[\"store_fe\"].var()\n",
    "var_storeXproduct = df_nonunique[\"storeXproduct_fe\"].var()\n",
    "var_storeXweek = df_nonunique[\"storeXweek_fe\"].var()\n",
    "var_productXweek = df_nonunique[\"productXweek_fe\"].var()\n",
    "\n",
    "# Residuals\n",
    "eps3 = model3.resid()    \n",
    "df_nonunique['resid_step3'] = eps3\n",
    "var_res = eps3.var()\n",
    "var_D  = df_nonunique[\"krone_ends_with_nine\"].var()\n",
    "# Variance shares\n",
    "shares = {\n",
    "    \"product\": var_p / var_D,\n",
    "    \"week\": var_t / var_D,\n",
    "    \"chain\": var_chain / var_D,\n",
    "    \"store\": var_store / var_D,\n",
    "    \"storeXproduct\": var_storeXproduct / var_D,\n",
    "    \"storeXweek\": var_storeXweek / var_D,\n",
    "    \"productXweek\": var_productXweek / var_D,\n",
    "    \"residual\": var_res / var_D\n",
    "}\n",
    "print(\"Variance shares:\")\n",
    "for k, v in shares.items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12f72f",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "- **Store × Product (0.4868)** — Almost half of the variation comes from which product is sold in which store. This means left-digit pricing is highly local and product-specific: the same product may follow different left-digit patterns across stores, and stores differ strongly in their pricing strategies across products.\n",
    "\n",
    "- **Product (0.2947)** — Nearly 30% of variation is purely across products. Some products are systematically more likely to use 9-endings or certain left digits, regardless of store or time.\n",
    "\n",
    "- **Product × Week (0.0814)** — Products exhibit time-varying price-ending patterns. Temporary promotions, seasonality, or product-specific pricing campaigns affect left-digit usage.\n",
    "\n",
    "- **Chain (0.0047)** and **Store (0.0011)** — Very little variation is explained by chain-wide or store-level policies alone. Chains do not appear to have strong uniform rules about left-digit pricing. Stores on average also don’t differ much unless you look at specific products.\n",
    "\n",
    "- **Week (0.0001)** — Almost no purely time-driven variation. There is no broad market-wide trend in left-digit usage over time.\n",
    "\n",
    "- **Store × Week (0.0042)** — Only a tiny amount comes from store-specific dynamics over time. Stores do not strongly change left-digit practices week by week.\n",
    "\n",
    "- **Residual (0.1397)** — Some idiosyncratic noise remains unexplained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance shares:\n",
      "product: 0.5129\n",
      "week: 0.0001\n",
      "residual: 0.6992\n",
      "store: 0.0066\n"
     ]
    }
   ],
   "source": [
    "# Extract FE dictionaries\n",
    "#theta_c = fe_dict[\"C(kjedeid)\"].values()\n",
    "# theta_store = fe_dict[\"C(store_id)\"].values()\n",
    "# theta_p = fe_dict[\"C(sku_gtin)\"].values()\n",
    "# theta_t = fe_dict[\"C(week)\"].values()\n",
    "\n",
    "# # Residuals\n",
    "# eps = model1.resid()\n",
    "# eps2 = df_nonunique[\"krone_ends_with_nine\"] - model1.predict() \n",
    "\n",
    "# # Variances\n",
    "# var_D  = df_nonunique[\"krone_ends_with_nine\"].var()\n",
    "# #theta_c_vals = np.array(list(theta_c))\n",
    "# #var_c  = np.var(theta_c_vals)\n",
    "# theta_store_vals = np.array(list(theta_store))\n",
    "# var_store  = np.var(theta_store_vals)\n",
    "# theta_p_vals = np.array(list(theta_p))\n",
    "# var_p  = np.var(theta_p_vals)\n",
    "# theta_t_vals = np.array(list(theta_t))\n",
    "# var_t  = np.var(theta_t_vals)\n",
    "# var_e  = np.var(eps2)\n",
    "\n",
    "# # Variance shares\n",
    "# shares = {\n",
    "#     #\"chain\":    var_c / var_D,\n",
    "#     \"product\": var_p / var_D,\n",
    "#     \"week\": var_t / var_D,\n",
    "#     \"residual\": var_e / var_D,\n",
    "#     \"store\": var_store / var_D\n",
    "# }\n",
    "\n",
    "# print(\"Variance shares:\")\n",
    "# for k, v in shares.items():\n",
    "#     print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e589860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 150.00 GB\n",
      "Available memory: 103.83 GB\n",
      "Used memory: 46.17 GB\n",
      "Memory usage: 30.8%\n"
     ]
    }
   ],
   "source": [
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506cb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
